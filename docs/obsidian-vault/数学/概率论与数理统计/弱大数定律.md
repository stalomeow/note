---
slug: "20240421213303"
date: "2024-04-21"
---

# 弱大数定律

弱大数定律（英文：Weak law of large numbers，简写：WLLN）也称为辛钦定理，陈述为：样本均值[[依概率收敛]]于期望。

相对地，还有强大数定律（英文：Strong law of large numbers，简写：SLLN）。

## Chebyshev LLN

若 $X_i$ 相互独立，具有相同的[[数学期望]]（$EX_i=\mu$），且存在常数 $C > 0$，使得 $DX_i \le C$ 则

$$
\frac{1}{n} \sum_{i=1}^{n} X_i \overset{P}{\longrightarrow} \mu, \  n \to \infty
$$

## Markov LLN

若 $\lim\limits_{n \to \infty} D \left [ \dfrac{1}{n} \displaystyle\sum\limits_{i=1}^{n} X_i \right ] = 0$ 则

$$
\frac{1}{n} \sum_{i=1}^{n} X_i \overset{P}{\longrightarrow} \frac{1}{n} \sum_{i=1}^{n} EX_i, \  n \to \infty
$$

## Khintchine LLN

若 $X_i$ 相互独立，同分布，具有有限的[[数学期望]]（$EX_i=\mu$）则

$$
\frac{1}{n} \sum_{i=1}^{n} X_i \overset{P}{\longrightarrow} \mu, \  n \to \infty
$$

## Bernoulli LLN

若 $n_A$ 表示 $n$ 重 Bernoulli 试验中事件 $A$ 发生的次数，且 $P(A)=p$ 则

$$
\frac{n_A}{n} \overset{P}{\longrightarrow} p, \  n \to \infty
$$
